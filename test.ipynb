{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Lambda, Cropping2D, Convolution2D, MaxPooling2D, Dropout, Activation\n",
    "\n",
    "from preprocess import get_data, extract_samples_from_rows, create_aug_img_pipeline, plot_data, plot_img, change_settings, generate_batch, settings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flipping is set to False\n",
      "extracted 69 samples from track1.\n",
      "extracted 8036 samples from data_ori.\n",
      "0 samples dropped based on 00 rules\n",
      "extracted 8105 samples total.\n",
      "8105  :: gotten total data amount ::  8105\n",
      "20  :: rows\n",
      "flipping is set to False\n",
      "extracted 69 samples from track1.\n",
      "extracted 8036 samples from data_ori.\n",
      "0 samples dropped based on 00 rules\n",
      "extracted 8105 samples total.\n"
     ]
    }
   ],
   "source": [
    "change_settings(\n",
    "    P_DROP_ZERO = 0.0,\n",
    "    #DROP_ZERO_HISTORY_LIM = 0,\n",
    "    SHUFFLE = True,\n",
    "    CHOOSE_ALL_CAMERAS = False,\n",
    "    DO_FILTER = True,\n",
    "    DO_FLIP = True,\n",
    "    P_FILTER = 0.98,\n",
    "    FILTER_BIN_SIZE = 0.01,\n",
    "    FILTER_BIN_TAKE_ABS = True,\n",
    "    \n",
    ")\n",
    "\n",
    "data, count = get_data()\n",
    "\n",
    "print (len(data), \" :: gotten total data amount :: \", count)\n",
    "\n",
    "import random\n",
    "\n",
    "i_st = random.randint(100, 3000)\n",
    "\n",
    "data_pl = data[i_st:i_st+20]\n",
    "print (len(data_pl), \" :: rows\")\n",
    "images, steers = extract_samples_from_rows(data, fake=True)\n",
    "\n",
    "change_settings(\n",
    "    DO_FILTER = False\n",
    ")\n",
    "\n",
    "data, count = get_data()\n",
    "images_un, steers_un = extract_samples_from_rows(data, fake=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.94269539999999996, 2)\n",
      "4365\n",
      "-1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ/8RIPAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f2876a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = list(zip(*np.unique(steers, return_counts=True)))\n",
    "count_dict = dict(stats)\n",
    "mx_count = max(stats, key=lambda x: x[1])[1]\n",
    "mx_value = max(stats, key=lambda x: abs(x[0]))[0]\n",
    "print (stats[1])\n",
    "print(mx_count)\n",
    "print (mx_value)\n",
    "stats = sorted(stats, key=lambda x: x[1])\n",
    "#print (stats)\n",
    "#print (sorted(stats, key=lambda x: abs(x[0])))\n",
    "\n",
    "\n",
    "#filter_by_count = \n",
    "#filter_by_value = \n",
    "[0.90, 0.00]\n",
    "[0, 1.15]\n",
    "[292, 1]\n",
    "#abs(value) = [0, 1.15]\n",
    "\n",
    "plot_data (steers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "[(-1.0, 6), (-0.94269539999999996, 2), (-0.93323809999999996, 1), (-0.92374369999999995, 1), (-0.85000010000000004, 6), (-0.80981139999999996, 1), (-0.77183400000000002, 1), (-0.72436219999999996, 1), (-0.69999999999999996, 12), (-0.68638480000000002, 2), (-0.63368119999999994, 4), (-0.6294187, 2), (-0.60093560000000001, 2), (-0.53447509999999998, 1), (-0.52498069999999997, 2), (-0.505992, 8), (-0.50000009999999995, 6), (-0.49649769999999999, 6), (-0.47750890000000001, 1), (-0.4680146, 2), (-0.45852019999999999, 1), (-0.45000000000000001, 4), (-0.44902579999999997, 17), (-0.43953150000000002, 12), (-0.4349402, 6), (-0.43003710000000001, 1), (-0.42537580000000003, 1), (-0.42054279999999999, 4), (-0.41104839999999998, 15), (-0.40155400000000002, 3), (-0.39946930000000003, 1), (-0.39205970000000001, 10), (-0.3825653, 8), (-0.37307099999999999, 10), (-0.35408230000000002, 9), (-0.3445879, 4), (-0.34234959999999998, 1), (-0.33509359999999999, 5), (-0.32559919999999998, 9), (-0.3215286, 1), (-0.31610480000000002, 14), (-0.30661050000000001, 9), (-0.30431900000000001, 1), (-0.29711609999999999, 43), (-0.28762179999999998, 38), (-0.27984959999999998, 1), (-0.27812740000000002, 31), (-0.26863310000000001, 18), (-0.2591387, 10), (-0.25007370000000001, 1), (-0.25, 1), (-0.24964430000000001, 11), (-0.24015, 9), (-0.23065559999999999, 36), (-0.22116130000000001, 41), (-0.21166689999999999, 56), (-0.2021725, 7), (-0.19973469999999999, 1), (-0.19267819999999999, 8), (-0.18318380000000001, 16), (-0.1817143, 1), (-0.1792453, 1), (-0.1736895, 20), (-0.16936909999999999, 1), (-0.16419510000000001, 36), (-0.15798200000000001, 1), (-0.1547008, 49), (-0.14751619999999999, 1), (-0.14520640000000001, 179), (-0.135712, 51), (-0.12621769999999999, 26), (-0.12573699999999999, 1), (-0.12175709999999999, 1), (-0.1167233, 55), (-0.1144973, 1), (-0.107229, 33), (-0.097877359999999997, 1), (-0.097734619999999994, 23), (-0.095776829999999993, 1), (-0.094597589999999995, 1), (-0.088240260000000001, 80), (-0.080225530000000003, 1), (-0.078745899999999994, 150), (-0.06925154, 129), (-0.059757190000000002, 152), (-0.050262830000000001, 61), (-0.040768470000000001, 46), (-0.031274110000000001, 38), (-0.021779759999999999, 49), (-0.0122854, 31), (-0.002791043, 79), (0.0, 4365), (0.0043487109999999999, 12), (0.013917240000000001, 74), (0.02348577, 53), (0.033054310000000003, 32), (0.042622840000000002, 106), (0.052191370000000001, 92), (0.0617599, 71), (0.071328440000000007, 92), (0.080896969999999999, 27), (0.090465500000000004, 165), (0.100034, 66), (0.10960259999999999, 19), (0.1191711, 23), (0.12873960000000001, 98), (0.13830819999999999, 37), (0.1478767, 31), (0.15744520000000001, 69), (0.16701379999999999, 136), (0.1765823, 237), (0.18615080000000001, 37), (0.19571939999999999, 28), (0.2052879, 14), (0.2148564, 25), (0.22442500000000001, 5), (0.23399349999999999, 11), (0.243562, 8), (0.25313059999999998, 14), (0.26269910000000002, 26), (0.2722676, 36), (0.28183619999999998, 12), (0.29140470000000002, 10), (0.3009732, 37), (0.31054169999999998, 17), (0.32011020000000001, 15), (0.32967879999999999, 2), (0.33924729999999997, 2), (0.34881580000000001, 28), (0.35838439999999999, 36), (0.36795290000000003, 20), (0.37752140000000001, 12), (0.38708999999999999, 3), (0.406227, 8), (0.41579559999999999, 2), (0.42536410000000002, 1), (0.4349326, 3), (0.44450119999999999, 1), (0.45406970000000002, 8), (0.4636382, 8), (0.47320679999999998, 4), (0.48277530000000002, 3), (0.4923438, 4), (0.51148090000000002, 6), (0.57846059999999999, 3), (0.58802920000000003, 3), (0.62630330000000001, 1), (0.63587179999999999, 1), (0.64544029999999997, 2), (0.65500890000000001, 1), (0.73155709999999996, 1), (1.0, 2)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ/8RIPAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121b94550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats_un = list(zip(*np.unique(steers_un, return_counts=True)))\n",
    "print(len(stats_un))\n",
    "print(sorted(stats_un))\n",
    "plot_data (steers_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-0.93323809999999996, 1), (-0.92374369999999995, 1), (-0.80981139999999996, 1), (-0.77183400000000002, 1), (-0.72436219999999996, 1), (-0.53447509999999998, 1), (-0.47750890000000001, 1), (-0.45852019999999999, 1), (-0.43003710000000001, 1), (-0.42537580000000003, 1), (-0.39946930000000003, 1), (-0.34234959999999998, 1), (-0.3215286, 1), (-0.30431900000000001, 1), (-0.27984959999999998, 1), (-0.25007370000000001, 1), (-0.25, 1), (-0.19973469999999999, 1), (-0.1817143, 1), (-0.1792453, 1), (-0.16936909999999999, 1), (-0.15798200000000001, 1), (-0.14751619999999999, 1), (-0.12573699999999999, 1), (-0.12175709999999999, 1), (-0.1144973, 1), (-0.097877359999999997, 1), (-0.095776829999999993, 1), (-0.094597589999999995, 1), (-0.080225530000000003, 1), (0.42536410000000002, 1), (0.44450119999999999, 1), (0.62630330000000001, 1), (0.63587179999999999, 1), (0.65500890000000001, 1), (0.73155709999999996, 1), (-0.94269539999999996, 2), (-0.68638480000000002, 2), (-0.6294187, 2), (-0.60093560000000001, 2), (-0.52498069999999997, 2), (-0.4680146, 2), (0.32967879999999999, 2), (0.33924729999999997, 2), (0.41579559999999999, 2), (0.64544029999999997, 2), (1.0, 2), (-0.40155400000000002, 3), (0.38708999999999999, 3), (0.4349326, 3), (0.48277530000000002, 3), (0.57846059999999999, 3), (0.58802920000000003, 3), (-0.63368119999999994, 4), (-0.45000000000000001, 4), (-0.42054279999999999, 4), (-0.3445879, 4), (0.47320679999999998, 4), (0.4923438, 4), (-0.33509359999999999, 5), (0.22442500000000001, 5), (-1.0, 6), (-0.85000010000000004, 6), (-0.50000009999999995, 6), (-0.49649769999999999, 6), (-0.4349402, 6), (0.51148090000000002, 6), (-0.2021725, 7), (-0.505992, 8), (-0.3825653, 8), (-0.19267819999999999, 8), (0.243562, 8), (0.406227, 8), (0.45406970000000002, 8), (0.4636382, 8), (-0.35408230000000002, 9), (-0.32559919999999998, 9), (-0.30661050000000001, 9), (-0.24015, 9), (-0.39205970000000001, 10), (-0.37307099999999999, 10), (-0.2591387, 10), (0.29140470000000002, 10), (-0.24964430000000001, 11), (0.23399349999999999, 11), (-0.69999999999999996, 12), (-0.43953150000000002, 12), (0.0043487109999999999, 12), (0.28183619999999998, 12), (0.37752140000000001, 12), (-0.31610480000000002, 14), (0.2052879, 14), (0.25313059999999998, 14), (-0.41104839999999998, 15), (0.32011020000000001, 15), (-0.18318380000000001, 16), (-0.44902579999999997, 17), (0.31054169999999998, 17), (-0.26863310000000001, 18), (0.10960259999999999, 19), (-0.1736895, 20), (0.36795290000000003, 20), (-0.097734619999999994, 23), (0.1191711, 23), (0.2148564, 25), (-0.12621769999999999, 26), (0.26269910000000002, 26), (0.080896969999999999, 27), (0.19571939999999999, 28), (0.34881580000000001, 28), (-0.27812740000000002, 31), (-0.0122854, 31), (0.1478767, 31), (0.033054310000000003, 32), (-0.107229, 33), (-0.23065559999999999, 36), (-0.16419510000000001, 36), (0.2722676, 36), (0.35838439999999999, 36), (0.13830819999999999, 37), (0.18615080000000001, 37), (0.3009732, 37), (-0.28762179999999998, 38), (-0.031274110000000001, 38), (-0.22116130000000001, 41), (-0.29711609999999999, 43), (-0.040768470000000001, 46), (-0.1547008, 49), (-0.021779759999999999, 49), (-0.135712, 51), (0.02348577, 53), (-0.1167233, 55), (-0.21166689999999999, 56), (-0.050262830000000001, 61), (0.100034, 66), (0.15744520000000001, 69), (0.0617599, 71), (0.013917240000000001, 74), (-0.002791043, 79), (-0.088240260000000001, 80), (0.052191370000000001, 92), (0.071328440000000007, 92), (0.12873960000000001, 98), (0.042622840000000002, 106), (-0.06925154, 129), (0.16701379999999999, 136), (-0.078745899999999994, 150), (-0.059757190000000002, 152), (0.090465500000000004, 165), (-0.14520640000000001, 179), (0.1765823, 237), (0.0, 4365)]\n"
     ]
    }
   ],
   "source": [
    "print (stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ/8RIPAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121bb9710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = generate_batch(data, fake=True, augment=False, flipit=True, rand_camera=True)\n",
    "\n",
    "images, steers = [], []\n",
    "\n",
    "for el in g:\n",
    "    images.extend(el[0])\n",
    "    steers.extend(el[1])\n",
    "    if len(images) >= count:\n",
    "        break\n",
    "\n",
    "#images, steers = extract_samples_from_rows(data, [0, 1, 2], [0, -0.15, 0.15], fake=True, )#rand=True)\n",
    "\n",
    "\n",
    "plot_data(steers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8105\n",
      "8105\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ/8RIPAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109cb0d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print (len(steers))\n",
    "change_settings(\n",
    "    AUGMENT_IMAGES=True, \n",
    "    SHEAR_SIGMA=settings[\"SHEAR_RANGE\"][1]/4, \n",
    "    SHEAR_ATAN_CORRECTION=20, \n",
    "    P_KEEP_ZERO=0.001,\n",
    "    DROP_ZERO_HISTORY_LIM=1,\n",
    ")\n",
    "\n",
    "aug_image = create_aug_img_pipeline(fake=True)\n",
    "images_a, steers_a = zip(*list(map(aug_image, images, steers)))\n",
    "print (len(steers))\n",
    "plot_data(steers_a)\n",
    "#plot_img(images_a[0])\n",
    "#plot_img(images[0])\n",
    "#print (images_a[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot_img(images_a[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image augmentations effects visualization\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "for i, el in enumerate(zip(images, steers)):\n",
    "    img, angle = el\n",
    "    a=fig.add_subplot(len(images)//2+1,2,(i+1))\n",
    "    imgplot = plt.imshow(img)\n",
    "    a.set_title(str(angle))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "column_names = ['center', 'left', 'right',\n",
    "                'steering', 'throttle', 'brake', 'speed']\n",
    "data_df = pd.read_csv('data/data_ori/driving_log.csv', skiprows=[0], names=column_names)\n",
    "data_df.iloc[:5]\n",
    "\n",
    "data_df['steering'][:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.figure()\n",
    "#data_df['steering'].plot.figure()\n",
    "data_df['steering'].plot.hist(bins=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TAN_CORRECT = 25\n",
    "aug_image = create_aug_img_pipeline(fake=True, accepted_angles=[0, 0.15, -0.15])\n",
    "plot_data(steers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "images_a, steers_a = zip(*list(map(aug_image, images, steers)))\n",
    "plot_data(steers_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print(images_a[0].shape)\n",
    "#print (sum(map(abs, rotate_net))/len(rotate_net))\n",
    "print (len(steers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data, count = get_data()\n",
    "init_data = data[:10]\n",
    "print ()\n",
    "sorted(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rows, cols, c = (33, 160, 3)\n",
    "\n",
    "def create_new_model():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x / 127.5 - 1.,\n",
    "              input_shape=(rows, cols, c),))\n",
    "    model.add(Convolution2D(24, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(.5))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "    model.add(Convolution2D(36, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(.5))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "    model.add(Convolution2D(48, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(.5))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(.5))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(.5))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1164))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(lr=learnrate)\n",
    "\n",
    "    # Patch change optimizer to mae. Research\n",
    "    model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=optimizer,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def lenet():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x / 127.5 - 1.,\n",
    "              input_shape=(rows, cols, c),))\n",
    "\n",
    "    model.add(Convolution2D(6, 5, 5, border_mode=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(.5))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(16, 5, 5, border_mode=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(.5))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Dense(120))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(84))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(lr=learnrate)\n",
    "\n",
    "    # Patch change optimizer to mae. Research\n",
    "    model.compile(\n",
    "        loss=\"mae\",\n",
    "        optimizer=optimizer,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def reload_model(epoch=None):\n",
    "    name = \"model.h5\"\n",
    "    if epoch:\n",
    "        name = \"model.h5_{}\".format(epoch)\n",
    "    return keras.models.load_model(name)\n",
    "\n",
    "\n",
    "model = reload_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flipping is set to False\n",
      "extracted 69 samples from track1.\n",
      "0 samples dropped based on 00 rules\n",
      "extracted 69 samples total.\n",
      "training 69 samples.\n",
      "validating 0 samples.\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 1s - loss: 0.2818\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 1s - loss: 0.2664\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 1s - loss: 0.2634\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 1s - loss: 0.2619\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 1s - loss: 0.2916\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 1s - loss: 0.2583\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 1s - loss: 0.2810\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 1s - loss: 0.2462\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 1s - loss: 0.2709\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 1s - loss: 0.2763\n",
      "training finished!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "# batch_size = 100\n",
    "learnrate = 0.00001 # 0.001 #\n",
    "\n",
    "# training_samples, training_sample_size, validation_samples, validation_sample_size = get_data(split_valid=0.25)\n",
    "training_samples, training_sample_size = get_data()\n",
    "#validation_samples, training_samples = samples[:len(samples) // 100], samples[len(samples) // 100:]\n",
    "\n",
    "#validation_sample_size = sample_count // 100\n",
    "# TODO add modifier\n",
    "#training_sample_size = sample_count - (validation_sample_size)\n",
    "\n",
    "# , INCLUDE_SIDES\n",
    "train_gen = generate_batch(training_samples)\n",
    "validation_gen = generate_batch(validation_samples, augment=False, flipit=True)\n",
    "\n",
    "print (\"training {} samples.\".format(training_sample_size))\n",
    "print (\"validating {} samples.\".format(validation_sample_size))\n",
    "\n",
    "# for i in range(cur_epoch, epochs):\n",
    "\n",
    "#     history_object = model.fit_generator(train_gen, samples_per_epoch=training_sample_size,\n",
    "#                                          nb_epoch=1, validation_data=validation_gen,\n",
    "#                                          nb_val_samples=validation_sample_size,)\n",
    "#     model_json = model.to_json()\n",
    "#     # with open(\"model.json\", \"w\") as json_file:\n",
    "#     #     json_file.write(model_json)\n",
    "#     print(\"saving model state at epoch: {}\".format(i+1))\n",
    "#     model.save(\"model.h5_{}\".format(i+1))\n",
    "history_object = model.fit_generator(train_gen, samples_per_epoch=training_sample_size,\n",
    "                                         nb_epoch=epochs,)\n",
    "#                                          validation_data=validation_gen,\n",
    "#                                          nb_val_samples=validation_sample_size,)\n",
    "print(\"training finished!!!!!!!!!!!!\")\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"model.h5\")\n",
    "\n",
    "# saving history object\n",
    "import pickle\n",
    "with open('history.pk', 'wb') as handle:\n",
    "    pickle.dump(history_object.history, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Lambda, Cropping2D, Convolution2D, MaxPooling2D, Dropout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# settings\n",
    "# limit images loaded in memory by setting batch limit for generator\n",
    "IMG_BATCH_SIZE = 128\n",
    "# path to folder where data is kept\n",
    "PATH_TO_DATA_FOLDER = 'data'\n",
    "# data heirachy should be one more dir deep as this may contain multiple dirs\n",
    "#   which contain different training data\n",
    "\n",
    "LOG_FILE = 'driving_log.csv'\n",
    "\n",
    "# for each dir entry, training data is fetched from corresponding subdirectory\n",
    "# TODO add all folders\n",
    "PATHS_TO_IMG_FOLDERS = ['data_center',] # 'data_ori', 'data_lap', 'data_reverse']\n",
    "#'data_ori']#, 'data_sides', 'data_lap', 'data_reverse']\n",
    "PATH_TO_IMG = 'IMG'\n",
    "\n",
    "# for each dir entry, all images found will be augmented by horizontal flip\n",
    "AUGMENT_DATA = ['data', 'data_2', 'data_center', 'data_ori', 'data_sides', 'data_lap', 'data_reverse']\n",
    "# for each dir entry, all images will be replicated dict value times\n",
    "# TODO change to 10\n",
    "# Should not be a multiple of 5 for keeping sample counts estimation simple\n",
    "MUTATE_DATA = {'data_center': 1, 'data_sides': 1}\n",
    "\n",
    "# inputs\n",
    "# center, left, right\n",
    "STEERING_CORRECTION_FACTORS = [0, 1.0 / 10, -1.0 / 10]\n",
    "\n",
    "# TODO set to True\n",
    "INCLUDE_SIDES = False\n",
    "# set to false to also augment side images\n",
    "AUGMENT_CENTER_ONLY = True\n",
    "\n",
    "# Mulitplier for counting total training samples after augmentation\n",
    "camera_sides = (3 if INCLUDE_SIDES else 1)\n",
    "AUGMENTED_SAMPLE_MULTIPLIER = camera_sides + (1 if AUGMENT_CENTER_ONLY else camera_sides)\n",
    "\n",
    "samples = []\n",
    "sample_count = 0\n",
    "for folder in PATHS_TO_IMG_FOLDERS:\n",
    "        log_file_path = os.path.join(PATH_TO_DATA_FOLDER, folder, LOG_FILE)\n",
    "        count = 0\n",
    "        with open(log_file_path) as logs:\n",
    "            reader = csv.reader(logs)\n",
    "            for row in reader:\n",
    "                if row[0] == \"center\":\n",
    "                    continue\n",
    "                row.append(folder)\n",
    "                samples.append(row)\n",
    "                count += 1\n",
    "        if folder in MUTATE_DATA:\n",
    "            count *= MUTATE_DATA[folder]\n",
    "        sample_count += count\n",
    "\n",
    "# count of total samples to be processed\n",
    "sample_count *= AUGMENTED_SAMPLE_MULTIPLIER\n",
    "\n",
    "\n",
    "# loading data\n",
    "def get_batch(samples, side_images=True):\n",
    "    \"\"\"Returns next (images, angle of steering) batch\"\"\"\n",
    "    while True:\n",
    "        samples = sklearn.utils.shuffle(samples)\n",
    "        count_b = 0\n",
    "        images = []\n",
    "        ang = []\n",
    "        for row in samples:\n",
    "            folder = row[-1]\n",
    "\n",
    "            # fetches image from given path\n",
    "            def get_img(img_entry):\n",
    "                path = os.path.join(PATH_TO_DATA_FOLDER, folder, PATH_TO_IMG,\n",
    "                                    img_entry.split('/')[-1])\n",
    "                return cv2.imread(path)\n",
    "\n",
    "            if side_images:\n",
    "                images_to_add = [get_img(row[i]) for i in range(3)]\n",
    "                angs_to_add = [float(row[3]) + offset for offset in STEERING_CORRECTION_FACTORS]\n",
    "            else:\n",
    "                images_to_add = [get_img(row[0]), ]\n",
    "                angs_to_add = [float(row[3]), ]\n",
    "\n",
    "            # augmenting image by flipping horizontally\n",
    "            if folder in AUGMENT_DATA:\n",
    "                if not AUGMENT_CENTER_ONLY:\n",
    "                    # augment all cameras\n",
    "                    images_to_add.extend([cv2.flip(image, 1) for image in images_to_add])\n",
    "                    angs_to_add.extend([angle * -1 for angle in angs_to_add])\n",
    "                else:\n",
    "                    # augment center camera image only\n",
    "                    images_to_add.append(cv2.flip(images_to_add[0], 1))\n",
    "                    angs_to_add.append(angs_to_add[0] * -1)\n",
    "\n",
    "            # mutating data by replicating it `n` times given by dict val\n",
    "            # TODO sample weights as replacement for replication?\n",
    "            if folder in MUTATE_DATA:\n",
    "                images_to_add = list(map(lambda x: x.copy(),\n",
    "                                         images_to_add * MUTATE_DATA[folder]))\n",
    "                angs_to_add = angs_to_add * MUTATE_DATA[folder]\n",
    "\n",
    "            # adding obtained data to list\n",
    "            images.extend(images_to_add)\n",
    "            ang.extend(angs_to_add)\n",
    "\n",
    "            # yielding current batch\n",
    "            if len(images) >= IMG_BATCH_SIZE:\n",
    "                count_b += len(images)\n",
    "                # TODO shuffle each batch?\n",
    "                print (len(images))\n",
    "                print (np.array(images).shape)\n",
    "                yield (np.array(images),\n",
    "                       np.array(ang))\n",
    "                images = []\n",
    "                ang = []\n",
    "\n",
    "        count_b += len(images)\n",
    "        print (len(images))\n",
    "        print (type(imges))\n",
    "        print (np.array(images).shape)\n",
    "        print (len(ang))\n",
    "        print (type(ang))\n",
    "        print (np.array(images).shape)\n",
    "        yield (np.array(images),\n",
    "               np.array(ang))\n",
    "\n",
    "\n",
    "# model\n",
    "# hyperparams\n",
    "epochs = 10\n",
    "# batch_size = 100\n",
    "learnrate = 0.001\n",
    "\n",
    "# layers\n",
    "layers = [\n",
    "    # preprocessing\n",
    "    Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160, 320, 3),),\n",
    "    Cropping2D(cropping=((60, 25), (0, 0))),\n",
    "\n",
    "    # conv 1\n",
    "    Convolution2D(6, 5, 5, border_mode='valid', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # conv 2\n",
    "    Convolution2D(16, 5, 5, border_mode='valid', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.5),\n",
    "\n",
    "#     # conv 3\n",
    "#     Convolution2D(16, 5, 5, border_mode='valid', activation='relu'),\n",
    "#     #MaxPooling2D((2, 2)),\n",
    "#     Dropout(0.5),\n",
    "\n",
    "#     # conv 4\n",
    "#     Convolution2D(8, 5, 5, border_mode='valid', activation='relu'),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Dropout(0.5),\n",
    "\n",
    "#     # conv 5\n",
    "#     Convolution2D(4, 5, 5, border_mode='valid', activation='relu'),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Dropout(0.5),\n",
    "\n",
    "    # flatten\n",
    "    Flatten(),\n",
    "\n",
    "#     # dense\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "\n",
    "#     # dense\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "\n",
    "    # dense\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # dense\n",
    "    Dense(1,),\n",
    "]\n",
    "\n",
    "# model compile\n",
    "model = Sequential(layers)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=learnrate)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=optimizer,\n",
    ")\n",
    "\n",
    "# shuffling samples\n",
    "# TODO change to inplace shuffling with np.random.shuffle\n",
    "samples = sklearn.utils.shuffle(samples)\n",
    "\n",
    "training_samples, validation_samples = samples[:len(samples) // 5], samples[len(samples) // 5:]\n",
    "\n",
    "validation_sample_size = sample_count // 5\n",
    "training_sample_size = sample_count - validation_sample_size\n",
    "\n",
    "train_gen = get_batch(training_samples, INCLUDE_SIDES)\n",
    "validation_gen = get_batch(validation_samples, INCLUDE_SIDES)\n",
    "\n",
    "print (\"training {} samples.\".format(sample_count))\n",
    "\n",
    "history_object = model.fit_generator(train_gen, samples_per_epoch=training_sample_size,\n",
    "                                     nb_epoch=epochs, validation_data=validation_gen,\n",
    "                                     nb_val_samples=validation_sample_size,)\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "# saving history object\n",
    "import pickle\n",
    "with open('history.pk', 'wb') as handle:\n",
    "    pickle.dump(history_object.history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "# plt.plot(history_object.history['loss'])\n",
    "# plt.plot(history_object.history['val_loss'])\n",
    "# plt.title('model mean squared error loss')\n",
    "# plt.ylabel('mean squared error loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "# plt.show()\n",
    "\n",
    "# model.save('model.h5')\n",
    "\n",
    "# TODO evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# behaviour cloning solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Lambda, Cropping2D, Convolution2D, MaxPooling2D, Dropout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# settings\n",
    "# limit images loaded in memory by setting batch limit for generator\n",
    "IMG_BATCH_SIZE = 128\n",
    "# path to folder where data is kept\n",
    "PATH_TO_DATA_FOLDER = 'data'\n",
    "# data heirachy should be one more dir deep as this may contain multiple dirs\n",
    "#   which contain different training data\n",
    "\n",
    "LOG_FILE = 'driving_log.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for each dir entry, training data is fetched from corresponding subdirectory\n",
    "# TODO add all folders\n",
    "PATHS_TO_IMG_FOLDERS = ['data_sides', 'data_ori', 'data_lap', 'data_reverse']\n",
    "#'data_ori']#, 'data_sides', 'data_lap', 'data_reverse']\n",
    "PATH_TO_IMG = 'IMG'\n",
    "\n",
    "# for each dir entry, all images found will be augmented by horizontal flip\n",
    "AUGMENT_DATA = ['data', 'data_2', 'data_center', 'data_ori', 'data_sides', 'data_lap', 'data_reverse']\n",
    "# for each dir entry, all images will be replicated dict value times\n",
    "# TODO change to 10\n",
    "# Should not be a multiple of 5 for keeping sample counts estimation simple\n",
    "MUTATE_DATA = {'data_center': 1, 'data_sides': 1}\n",
    "\n",
    "# inputs\n",
    "# center, left, right\n",
    "STEERING_CORRECTION_FACTORS = [0, 1.0 / 10, -1.0 / 10]\n",
    "\n",
    "# TODO set to True\n",
    "INCLUDE_SIDES = False\n",
    "# set to false to also augment side images\n",
    "AUGMENT_CENTER_ONLY = True\n",
    "\n",
    "# Mulitplier for counting total training samples after augmentation\n",
    "camera_sides = (3 if INCLUDE_SIDES else 1)\n",
    "AUGMENTED_SAMPLE_MULTIPLIER = camera_sides + (1 if AUGMENT_CENTER_ONLY else camera_sides)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Visualize Data\n",
    "\n",
    "View a sample from the dataset.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "samples = []\n",
    "sample_count = 0\n",
    "for folder in PATHS_TO_IMG_FOLDERS:\n",
    "        log_file_path = os.path.join(PATH_TO_DATA_FOLDER, folder, LOG_FILE)\n",
    "        count = 0\n",
    "        with open(log_file_path) as logs:\n",
    "            reader = csv.reader(logs)\n",
    "            for row in reader:\n",
    "                if row[0] == \"center\":\n",
    "                    continue\n",
    "                row.append(folder)\n",
    "                samples.append(row)\n",
    "                count += 1\n",
    "        if folder in MUTATE_DATA:\n",
    "            count *= MUTATE_DATA[folder]\n",
    "        sample_count += count\n",
    "\n",
    "# count of total samples to be processed\n",
    "sample_count *= AUGMENTED_SAMPLE_MULTIPLIER\n",
    "\n",
    "\n",
    "# loading data\n",
    "def get_batch(samples, side_images=True):\n",
    "    \"\"\"Returns next (images, angle of steering) batch\"\"\"\n",
    "    while True:\n",
    "        samples = sklearn.utils.shuffle(samples)\n",
    "        count_b = 0\n",
    "        images = []\n",
    "        ang = []\n",
    "        for row in samples:\n",
    "            folder = row[-1]\n",
    "\n",
    "            # fetches image from given path\n",
    "            def get_img(img_entry):\n",
    "                path = os.path.join(PATH_TO_DATA_FOLDER, folder, PATH_TO_IMG,\n",
    "                                    img_entry.split('/')[-1])\n",
    "                return cv2.imread(path)\n",
    "\n",
    "            if side_images:\n",
    "                images_to_add = [get_img(row[i]) for i in range(3)]\n",
    "                angs_to_add = [float(row[3]) + offset for offset in STEERING_CORRECTION_FACTORS]\n",
    "            else:\n",
    "                images_to_add = [get_img(row[0]), ]\n",
    "                angs_to_add = [float(row[3]), ]\n",
    "\n",
    "            # augmenting image by flipping horizontally\n",
    "            if folder in AUGMENT_DATA:\n",
    "                if not AUGMENT_CENTER_ONLY:\n",
    "                    # augment all cameras\n",
    "                    images_to_add.extend([cv2.flip(image, 1) for image in images_to_add])\n",
    "                    angs_to_add.extend([angle * -1 for angle in angs_to_add])\n",
    "                else:\n",
    "                    # augment center camera image only\n",
    "                    images_to_add.append(cv2.flip(images_to_add[0], 1))\n",
    "                    angs_to_add.append(angs_to_add[0] * -1)\n",
    "\n",
    "            # mutating data by replicating it `n` times given by dict val\n",
    "            # TODO sample weights as replacement for replication?\n",
    "            if folder in MUTATE_DATA:\n",
    "                images_to_add = list(map(lambda x: x.copy(),\n",
    "                                         images_to_add * MUTATE_DATA[folder]))\n",
    "                angs_to_add = angs_to_add * MUTATE_DATA[folder]\n",
    "\n",
    "            # adding obtained data to list\n",
    "            images.extend(images_to_add)\n",
    "            ang.extend(angs_to_add)\n",
    "\n",
    "            # yielding current batch\n",
    "            if len(images) >= IMG_BATCH_SIZE:\n",
    "                count_b += len(images)\n",
    "                # TODO shuffle each batch?\n",
    "                yield (np.array(images),\n",
    "                       np.array(ang))\n",
    "                images = []\n",
    "                ang = []\n",
    "\n",
    "        count_b += len(images)\n",
    "        yield (np.array(images),\n",
    "               np.array(ang))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess Data\n",
    "\n",
    "Shuffle the training data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# model\n",
    "# hyperparams\n",
    "epochs = 10\n",
    "# batch_size = 100\n",
    "learnrate = 0.001\n",
    "\n",
    "# layers\n",
    "layers = [\n",
    "    # preprocessing\n",
    "    Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160, 320, 3),),\n",
    "    Cropping2D(cropping=((60, 25), (0, 0))),\n",
    "\n",
    "    # conv 1\n",
    "    Convolution2D(32, 5, 5, border_mode='valid', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # conv 2\n",
    "    Convolution2D(16, 5, 5, border_mode='valid', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # conv 3\n",
    "    Convolution2D(16, 5, 5, border_mode='valid', activation='relu'),\n",
    "    #MaxPooling2D((2, 2)),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # conv 4\n",
    "    Convolution2D(8, 5, 5, border_mode='valid', activation='relu'),\n",
    "    #MaxPooling2D((2, 2)),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # conv 5\n",
    "    Convolution2D(4, 5, 5, border_mode='valid', activation='relu'),\n",
    "    #MaxPooling2D((2, 2)),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # flatten\n",
    "    Flatten(),\n",
    "\n",
    "    # dense\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # dense\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # dense\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # dense\n",
    "    Dense(1,),\n",
    "]\n",
    "\n",
    "# model compile\n",
    "model = Sequential(layers)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=learnrate)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=optimizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup TensorFlow\n",
    "The `EPOCH` and `BATCH_SIZE` values affect the training speed and model accuracy.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# shuffling samples\n",
    "# TODO change to inplace shuffling with np.random.shuffle\n",
    "samples = sklearn.utils.shuffle(samples)\n",
    "\n",
    "training_samples, validation_samples = samples[:len(samples) // 5], samples[len(samples) // 5:]\n",
    "\n",
    "validation_sample_size = sample_count // 5\n",
    "training_sample_size = sample_count - validation_sample_size\n",
    "\n",
    "train_gen = get_batch(training_samples, INCLUDE_SIDES)\n",
    "validation_gen = get_batch(validation_samples, INCLUDE_SIDES)\n",
    "\n",
    "print (\"training {} samples.\".format(sample_count))\n",
    "\n",
    "history_object = model.fit_generator(train_gen, samples_per_epoch=training_sample_size,\n",
    "                                     nb_epoch=epochs, validation_data=validation_gen,\n",
    "                                     nb_val_samples=validation_sample_size,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## SOLUTION: Implement LeNet-5\n",
    "Implement the [LeNet-5](http://yann.lecun.com/exdb/lenet/) neural network architecture.\n",
    "\n",
    "This is the only cell you need to edit.\n",
    "### Input\n",
    "The LeNet architecture accepts a 32x32xC image as input, where C is the number of color channels. Since MNIST images are grayscale, C is 1 in this case.\n",
    "\n",
    "### Architecture\n",
    "**Layer 1: Convolutional.** The output shape should be 28x28x6.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 14x14x6.\n",
    "\n",
    "**Layer 2: Convolutional.** The output shape should be 10x10x16.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 5x5x16.\n",
    "\n",
    "**Flatten.** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using `tf.contrib.layers.flatten`, which is already imported for you.\n",
    "\n",
    "**Layer 3: Fully Connected.** This should have 120 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 4: Fully Connected.** This should have 84 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 5: Fully Connected (Logits).** This should have 10 outputs.\n",
    "\n",
    "### Output\n",
    "Return the result of the 2nd fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # SOLUTION: Layer 1: Convolutional. Input = 32x32x3. Output = 28x28x6.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, 6), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Flatten. Input = 5x5x16. Output = 400.\n",
    "    fc0   = flatten(conv2)\n",
    "    \n",
    "    # SOLUTION: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "\n",
    "    # SOLUTION: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(84))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = 84. Output = 43.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Features and Labels\n",
    "Train LeNet to classify [MNIST](http://yann.lecun.com/exdb/mnist/) data.\n",
    "\n",
    "`x` is a placeholder for a batch of input images.\n",
    "`y` is a placeholder for a batch of output labels.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training Pipeline\n",
    "Create a training pipeline that uses the model to classify MNIST data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model Evaluation\n",
    "Evaluate how well the loss and accuracy of the model for a given dataset.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Model\n",
    "Run the training data through the training pipeline to train the model.\n",
    "\n",
    "Before each epoch, shuffle the training set.\n",
    "\n",
    "After each epoch, measure the loss and accuracy of the validation set.\n",
    "\n",
    "Save the model after training.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluate the Model\n",
    "Once you are completely satisfied with your model, evaluate the performance of the model on the test set.\n",
    "\n",
    "Be sure to only do this once!\n",
    "\n",
    "If you were to measure the performance of your trained model on the test set, then improve your model, and then measure the performance of your model on the test set again, that would invalidate your test results. You wouldn't get a true measure of how well your model would perform against real data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
